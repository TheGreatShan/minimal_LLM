{
    "ContextSize": 4096,
    "Seed": 1337,
    "GpuLayerCount": 5,
    "MaxTokens": 2048,
    "Temperature": 0.8,
    "RepeatPenalty": 1.1,
    "Model": "mistral-7b-v0.1.Q3_K_M.gguf",
    "Prompt": "prompt.txt"
}
  